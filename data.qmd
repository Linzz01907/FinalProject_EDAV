# Data

```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(tidyverse)
library(heatmaply)
library(readxl)
library(knitr)
```

```{r echo=FALSE}
salary=read.csv('Citywide_Payroll_Data__Fiscal_Year_ (1).csv')
#delete meaningless data
salary=salary[, -which(colnames(salary) %in% c("Payroll.Number","Last.Name","First.Name","Mid.Init"))]
```

## Description

Data sources: The Citywide Payroll dataset is from NYC OpenData website. https://data.cityofnewyork.us/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e/data

Data collection: Data Provided by Office of Payroll Administration (OPA). Data is input into the City's Personnel Management System ("PMS") by the respective user Agencies. It includes the agency information, salary and overtimepay for all municipal employees in New York.

Data description: Data is collected because of public interest in how the City's budget is being spent on salary and overtime pay for all municipal employees. We will describe it in 6 parts.

### Data Format

We summarize it by a csv file.

```{r message=FALSE, warning=FALSE}
description<-read_csv('data_description.csv')
kable(description)
```

### Frequency of updates

It is updated annually.

### Dimension

5662713\*13

### Data range

For numerical data, we will show the upper bound and lower bound.

```{r}
max_values <- apply(salary[c("Fiscal.Year","Base.Salary","Regular.Hours","Regular.Gross.Paid","OT.Hours","Total.OT.Paid")], 2, max)
min_values <- apply(salary[c("Fiscal.Year","Base.Salary","Regular.Hours","Regular.Gross.Paid","OT.Hours","Total.OT.Paid")], 2, min)
print('upper bound')
print(max_values)
print('lower bound')
print(min_values)
```

For categorical data, we will show all labels and counts.

```{r}
#table(salary[c("Agency.Name")])
salary$Work.Location.Borough <- toupper(salary$Work.Location.Borough)
table(salary[c("Work.Location.Borough")])
#table(salary[c("Title.Description")])
table(salary[c("Leave.Status.as.of.June.30")])
```


### Issues/problems with the data

There exists negative regular hours and OT hours and agency start date exists 12/31/9999.

### How to impute data

We download Citywide Payroll dataset on NYC OpenData website in 'csv' format and impute it by read.csv function directly and the link of our data source is https://data.cityofnewyork.us/City-Government/Citywide-Payroll-Data-Fiscal-Year-/k397-673e/data

## Research Plan

Based on our research questions regarding various factors influencing salary levels and overtime situations in the workplace, we will divide our project into three parts, including individual factor analysis, multi-factor mixed analysis and overtime analysis.

### Individual Factor Analysis

First, we aim to examine the factors that influence salary. These factors encompass year, agency, agency start date, work location, job title, pay basis, and leave status at the end of the fiscal year. Additionally, base salary, and regular gross paid are considered. Altogether, we have nine influencing factors. Our goal is to understand not only the impact of each individual factor on salary but also the combined effect of multiple factors on salary.

We begin by analyzing the individual factors affecting salary. Concerning year trends and patterns, we aim to understand how salaries have evolved over the past ten years and identify any noticeable trends in employee compensation during specific periods, such as economic downturns or budget cuts. The 'Year' field allows for a temporal analysis, facilitating year-over-year comparisons of salaries, thereby revealing trends and patterns over time. Next, we will conduct an agency-specific analysis. Given the potential for significant salary differences across agencies, we seek to determine which agencies have the highest and lowest salaries and understand the reasons behind these disparities. Here, we need to pay attention that low salary accompanied by fewer regular work hours may be indicative by a part-time job. The 'Agency Name' field will be used to group data by agency, enabling comparisons of salaries across different departments or units. Regarding the impact of agency start time, we will explore whether the length of time an agency has been operational affects its employees' salaries. Analysis of the 'Agency Start Date' will help investigate if newer agencies offer different pay scales compared to well-established ones.

We will also examine geographical disparities, job title, and compensation analysis, as well as the impact of leave status and pay basis on compensation. We will explore how factors like work location, job title, leave status, and pay basis affect salaries. The 'Work Location Borough' field will assist in examining if geographic factors influence compensation, considering cost-of-living variations across different boroughs. 'Job Title Description' allows for an analysis of salary and overtime payments by role, identifying positions with higher compensation and the reasons behind it. 'Leave Status' at the fiscal year's end will be correlated with total compensation to understand how leave impacts an employee's overall earnings. 'Pay Basis' (monthly, yearly, hourly) will be correlated with overall compensation to understand how different payment structures affect total earnings.

### Multi-Factor Mixed Analysis

Finally, we will conduct an analysis of salary encompassing multiple elements. Concerning base salary and other factors, we aim to explore trends in base salaries across various job titles and agencies. Key questions include how the base salary relates to the total amount paid during the fiscal year and how it correlates with total compensation. To investigate this, we will employ data from multiple columns using methods such as group by. The 'Base Salary' field is essential for analyzing salary trends across different roles and agencies and understanding its relationship with total compensation. By examining both 'Base Salary' and 'Total Gross Paid', we can discern the proportion of earnings derived from base pay as opposed to overtime and other forms of compensation. Here we plan to choose mosaic and slope graph as analysis tool.

### Overtime Analysis

In this part, we are curious that this overtime work module in different work field or work year. Here we will create a new column called 'agency size' based on calculating the number of staffs in different agencies and we will add it into our influence factor test as well. To solve it, we identify patterns and causes of overtime across agencies and job titles by aggregating overtime hours and salaries by job title and agency(agency field, agency start time,year,Work location, agency size), we can highlight where overtime is most common. As for trends in overtime hours and overtime paid: By analyzing 'OT Hours' and 'OT Paid' across different fiscal years, we can detect any increasing or decreasing trends in overtime. Line graph for overtime hours&salaries is the optimal method to identify their trends over time.

We also explore the ratio of regular to overtime hours&salaries across different agencies. We can calculate this ratio for each agency by aggregating 'Regular Hours'&'Base Salary' and 'OT Hours'&'OT Paid' and then compare across agencies. Heatmap is one of our methods to demonstrate the distribution and prevalence of overtime across different job titles and agencies, identifying hotspots. After finishing it, we can compare the consistence of high ration and high overtime hours&salaries by bubble chart where the position on the x-axis can represent overtime hours, the y-axis for the overtime ratio, and the bubble size for agencies or job titles.

## Missing value analysis

```{r}
salary <- salary %>%
      mutate(across(where(is.character), ~na_if(., "")))
missing_values <- sapply(salary, function(x) sum(is.na(x)))
print(missing_values)

# Creating the bar chart
ggplot(data = data.frame(Column = names(missing_values), MissingValues = missing_values),
       aes(x = Column, y = MissingValues)) +
    geom_bar(stat = "identity") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
    labs(x = "Column Name", y = "Number of Missing Values", title = "Missing Values per Column")

library(redav)
df<-salary
colnames(df) <- substr(colnames(df), 1, 4)
plot_missing(df)

```




After we delete meaningless data like "Payroll.Number", "Last.Name", "First.Name", "Mid.Init", there is no missing data in our data set.


```{r}
 
salary_cleaned = na.omit(salary)
colSums(is.na(salary_cleaned)) |> sort(decreasing=TRUE)
write.csv(salary_cleaned, "~/edav_lz_sm/Cleaned Dataset.csv", row.names=FALSE)
```

